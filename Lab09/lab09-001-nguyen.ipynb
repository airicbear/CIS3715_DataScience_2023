{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9: Document Analysis\n",
    "\n",
    "In this assignment, we will learn how to do document classification and clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example\n",
    "\n",
    "In this example, we use [20newsgroups](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset) dataset. Each sample is a document and there are totally 20 classes. \n",
    "\n",
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data target labels: [7 4 4 ... 3 1 8]\n",
      "Train data target names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "#training samples: 11314\n",
      "#testing samples: 7532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "data_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print(\"Train data target labels: {}\".format(data_train.target))\n",
    "print(\"Train data target names: {}\".format(data_train.target_names))\n",
    "\n",
    "print('#training samples: {}'.format(len(data_train.data)))\n",
    "print('#testing samples: {}'.format(len(data_test.data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Represent documents with TF-IDF represention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631) (7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#TF-IDF representation for each document\n",
    "vectorizer = TfidfVectorizer()\n",
    "data_train_vectors = vectorizer.fit_transform(data_train.data)\n",
    "data_test_vectors = vectorizer.transform(data_test.data) \n",
    "\n",
    "print(data_train_vectors.shape, data_test_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use KNN to do document classification\n",
    "\n",
    "Here, we use the cross-validation method to select $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13620293441753578\n",
      "{'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "Xtr = data_train_vectors\n",
    "Ytr = data_train.target\n",
    "\n",
    "Xte = data_test_vectors\n",
    "Yte = data_test.target\n",
    "\n",
    "k_range = range(1, 2)\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "grid = GridSearchCV(clf_knn, param_grid, cv=2, scoring='accuracy')\n",
    "grid.fit(Xtr, Ytr)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use Logistic Regression to do document classification\n",
    "Here, we also use the cross-validation method to select the regularization coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.6736590546999469 0.6585894332744863 0.6736590546999469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "#=====training with cross validation======\n",
    "coeff = range(1, 2)\n",
    "param_grid = dict(C=coeff)\n",
    "\n",
    "clf_lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "grid = GridSearchCV(clf_lr, param_grid, cv=2, scoring='accuracy')\n",
    "grid.fit(Xtr, Ytr)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "#=====testing======\n",
    "clf_lr = LogisticRegression(penalty='l2', C=grid.best_params_['C'])\n",
    "clf_lr.fit(Xtr, Ytr)\n",
    "\n",
    "y_pred = clf_lr.predict(Xte)\n",
    "\n",
    "acc = accuracy_score(Yte, y_pred)\n",
    "macro_f1 = f1_score(Yte, y_pred, average='macro')\n",
    "micro_f1 = f1_score(Yte, y_pred, average='micro')\n",
    "\n",
    "print(acc, macro_f1, micro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task: Document Classification and Clustering\n",
    "\n",
    "In this task, we are going to use [BBCNews](BBC_News_Train.csv) dataset. There are 1490 articles from 5 topics, including tech, business, sport, entertainment, politics. \n",
    "\n",
    "* Task 1: Please use KNN and logistic regression to do classification, and compare their performance.\n",
    "\n",
    "* Task 2: Please use K-means to partition this dataset into 5 clusters and find the representative words in each cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load data and represent it with TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bbcnews_df = pd.read_csv('BBC_News_Train.csv')\n",
    "\n",
    "bbcnews_text = bbcnews_df['Text']\n",
    "bbcnews_target = bbcnews_df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bbcnews_text,\n",
    "                                                    bbcnews_target.values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Use KNN to do document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9270173341303047\n",
      "{'n_neighbors': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_range = range(1, 5)\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "grid = GridSearchCV(clf_knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train_vec, y_train)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Use Logistic Regression to do document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 8}\n",
      "0.9697986577181208 0.9708405690370728 0.9697986577181208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "#=====training with cross validation======\n",
    "coeff = range(1, 10)\n",
    "param_grid = dict(C=coeff)\n",
    "\n",
    "clf_lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "grid = GridSearchCV(clf_lr, param_grid, cv=2, scoring='accuracy')\n",
    "grid.fit(X_train_vec, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "#=====testing======\n",
    "clf_lr = LogisticRegression(penalty='l2', C=grid.best_params_['C'])\n",
    "clf_lr.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf_lr.predict(X_test_vec)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(acc, macro_f1, micro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Use K-means to do document clustering and find the 10 most representative words in each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business', 'entertainment', 'politics', 'sport', 'tech'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(bbcnews_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericnguyen/opt/anaconda3/envs/cis-3715/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster = KMeans(n_clusters=5, random_state=0).fit(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22292</th>\n",
       "      <th>22293</th>\n",
       "      <th>22294</th>\n",
       "      <th>22295</th>\n",
       "      <th>22296</th>\n",
       "      <th>22297</th>\n",
       "      <th>22298</th>\n",
       "      <th>22299</th>\n",
       "      <th>22300</th>\n",
       "      <th>22301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6       \n",
       "0  0.000302  0.010411  0.000000  0.000000  0.000000  0.000000  0.000000  \\\n",
       "1  0.000379  0.013690  0.000000  0.000000  0.000000  0.000000  0.000801   \n",
       "2  0.000000  0.009528  0.000261  0.000000  0.000000  0.000845  0.000000   \n",
       "3  0.000000  0.011289  0.000000  0.000322  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.003176  0.000000  0.000000  0.004879  0.000000  0.000000   \n",
       "\n",
       "    7         8         9      ...   22292     22293     22294     22295   \n",
       "0  0.0000  0.000000  0.000292  ...  0.0002  0.000324  0.000603  0.000583  \\\n",
       "1  0.0004  0.000000  0.000000  ...  0.0000  0.000000  0.000000  0.000000   \n",
       "2  0.0000  0.000469  0.000000  ...  0.0000  0.000000  0.000000  0.000000   \n",
       "3  0.0000  0.000000  0.000000  ...  0.0000  0.000736  0.000000  0.000000   \n",
       "4  0.0000  0.000000  0.000000  ...  0.0000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      22296    22297     22298     22299     22300     22301  \n",
       "0  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000257  0.00056  0.000000  0.000000  0.000486  0.000000  \n",
       "3  0.000000  0.00000  0.000000  0.000262  0.000000  0.000000  \n",
       "4  0.000000  0.00000  0.000135  0.001430  0.000000  0.000964  \n",
       "\n",
       "[5 rows x 22302 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_representation_df = pd.DataFrame(X_train_vec.todense()).groupby(cluster.labels_).mean()\n",
    "term_representation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: ['microsoft', 'broadband', 'technology', 'net', 'software', 'users', 'phone', 'said', 'people', 'mobile']\n",
      "Cluster 1: ['howard', 'minister', 'government', 'brown', 'party', 'said', 'blair', 'election', 'labour', 'mr']\n",
      "Cluster 2: ['festival', 'star', 'award', 'actor', 'band', 'music', 'said', 'awards', 'best', 'film']\n",
      "Cluster 3: ['oil', 'market', 'firm', 'government', 'bank', 'economy', 'year', 'mr', 'growth', 'said']\n",
      "Cluster 4: ['players', 'chelsea', 'season', 'match', 'world', 'cup', 'win', 'said', 'game', 'england']\n"
     ]
    }
   ],
   "source": [
    "term_representation_df = pd.DataFrame(X_train_vec.todense()).groupby(cluster.labels_).mean()\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i, r in term_representation_df.iterrows():\n",
    "    sorted_row = np.argsort(r)\n",
    "    top_10_sorted_row = sorted_row[-10:]\n",
    "    top_10 = [terms[t] for t in top_10_sorted_row]\n",
    "    print(f'Cluster {i}: {top_10}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
